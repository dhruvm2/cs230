{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTE: THE MAJORITY OF THIS CODE COMES FROM THE CODE FOR THE TENSORFLOW TUTORIAL IN COURSE 2. IT HAS BEEN INVALUABLE IN THE CREATION OF THIS PROJECT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stream_data = pd.read_csv('stream_data.csv', quotechar='\"', skipinitialspace=True).values\n",
    "rank_data = pd.read_csv('rank_data.csv', quotechar='\"', skipinitialspace=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n"
     ]
    }
   ],
   "source": [
    "n=stream_data.shape[0]\n",
    "d=stream_data.shape[1]\n",
    "\n",
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    for j in range(3,d):\n",
    "        if(d>= j+37):\n",
    "            if(np.sum([np.isnan(x) for x in stream_data[i][j:(j+30)]]) == 0):\n",
    "                x_data = []\n",
    "                x_data.extend(stream_data[i][j:(j+30)])\n",
    "                x_data.extend(rank_data[i][j:(j+30)])\n",
    "                x_data.extend([(1.0 if stream_data[i][j+k+1]>stream_data[i][j+k] else 0.0) for k in range(29)])\n",
    "                x_data.extend([(1.0 if rank_data[i][j+k+1]>rank_data[i][j+k] else 0.0) for k in range(29)])\n",
    "                day = np.zeros(6)\n",
    "                if(j%7 < 6):\n",
    "                    day[j%7] = 1.0\n",
    "                x_data.extend(day)\n",
    "                \n",
    "                y_data=[]\n",
    "                y_data.extend(stream_data[i][(j+30):(j+37)])\n",
    "                \n",
    "                if(all(isinstance(item, float) for item in y_data)):\n",
    "                    if(np.sum(np.isnan(y_data))==0):\n",
    "                        X.append(x_data)\n",
    "                        Y.append(y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:14: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:15: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:16: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:17: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "\n",
    "X = X[s]\n",
    "Y = Y[s]\n",
    "\n",
    "m = X.shape[0]\n",
    "\n",
    "cutoff = np.floor(m*4/5)\n",
    "\n",
    "X_train = X[:cutoff]\n",
    "Y_train = Y[:cutoff]\n",
    "X_test = X[cutoff:]\n",
    "Y_test = Y[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cost\n",
    "\n",
    "def cost(logits, actual):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    \n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (predicted number of streams)\n",
    "    actual -- vector containing actual number of streams\n",
    "    \n",
    "    Returns:\n",
    "    cost -- runs the session of the cost (formula (2))\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    # Create the placeholders for \"logits\" (z) and \"labels\" (y) (approx. 2 lines)\n",
    "    z = tf.placeholder(tf.float32, name = \"z\")\n",
    "    y = tf.placeholder(tf.float32, name = \"y\")\n",
    "    \n",
    "    # Use the loss function (approx. 1 line)\n",
    "    \n",
    "    cost = tf.reduce_mean((z/y - 1)**2)\n",
    "    \n",
    "    # Create a session (approx. 1 line). See method 1 above.\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line).\n",
    "    cost = sess.run(cost, feed_dict = {z: logits, y: actual})\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape=(n_x, None))\n",
    "    Y = tf.placeholder(tf.float32, shape=(n_y, None))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [1, 124]\n",
    "                        b1 : [1, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [1,124], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [1,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z1 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                             \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z1, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean((Z1/Y - 1)**2)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z1 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z1, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.778391\n",
      "Cost after epoch 10: 0.020180\n",
      "Cost after epoch 20: 0.011373\n",
      "Cost after epoch 30: 0.004982\n",
      "Cost after epoch 40: 0.003582\n",
      "Cost after epoch 50: 0.003129\n",
      "Cost after epoch 60: 0.002885\n",
      "Cost after epoch 70: 0.002749\n",
      "Cost after epoch 80: 0.002643\n",
      "Cost after epoch 90: 0.002575\n",
      "Cost after epoch 100: 0.002519\n",
      "Cost after epoch 110: 0.002485\n",
      "Cost after epoch 120: 0.002443\n",
      "Cost after epoch 130: 0.002424\n",
      "Cost after epoch 140: 0.002403\n",
      "Cost after epoch 150: 0.002379\n",
      "Cost after epoch 160: 0.002366\n",
      "Cost after epoch 170: 0.002343\n",
      "Cost after epoch 180: 0.002329\n",
      "Cost after epoch 190: 0.002321\n",
      "Cost after epoch 200: 0.002318\n",
      "Cost after epoch 210: 0.002305\n",
      "Cost after epoch 220: 0.002291\n",
      "Cost after epoch 230: 0.002287\n",
      "Cost after epoch 240: 0.002289\n",
      "Cost after epoch 250: 0.002271\n",
      "Cost after epoch 260: 0.002268\n",
      "Cost after epoch 270: 0.002265\n",
      "Cost after epoch 280: 0.002268\n",
      "Cost after epoch 290: 0.002263\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1f8A5oJ8yQTfVIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0be0136dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train.T, np.matrix(Y_train[:,0]), X_test.T, np.matrix(Y_test[:,0]),learning_rate = 0.0002,minibatch_size = 100,num_epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = parameters['W1']\n",
    "b1 = parameters['b1']\n",
    "\n",
    "Y_hat = (W1.dot(X_test.T) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11082.048928387019"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((np.abs(np.matrix(Y_test[:,0]) - Y_hat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
